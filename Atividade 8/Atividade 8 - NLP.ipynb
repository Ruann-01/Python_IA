{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução a NLP\n",
    "Nessa atividade vocês irão trabalhar em um problema de classificação de texto multiclasse. Considere o conjunto de dados sobre fetch_20newsgroups  \n",
    "\n",
    "\"The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\"\n",
    "\n",
    "Esse conjunto de dados pode ser carregado através so scikit-learn\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', \n",
    "                                 shuffle=True, random_state=42)\n",
    "\n",
    "Dado esse contexto, escolha um único classificador, sem otimizar hiperparametros, treine e teste modelos considerando\n",
    "- Bag of Words (contagem), sem pré-processamento\n",
    "- TF-IDF, sem pré-processamento \n",
    "- Bag of Words, com pré-processamento\n",
    "- TF-IDF, com pré-processamento\n",
    "- Considere a métrica da acurácia e compare os resultados em uma tabela.\n",
    "\n",
    "As etapas de pré-processamento devem conter pelo menos:\n",
    "- lowercase\n",
    "- remoção de pontuação\n",
    "- remoção de números \n",
    "- remoção de stopwords (dica: utilize a biblioteca NLTK)\n",
    "- lematização ou stemming (apenas um dos dois)\n",
    "\n",
    "Outras etapas que você julgar necessárias podem ser utilizadas. Crie uma função para cada etapa e uma função chamada preprocess() que chame todas as etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ruann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ruann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ruann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = twenty_train['data']\n",
    "y_train = twenty_train['target']\n",
    "text_test = twenty_test['data']\n",
    "y_test = twenty_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo extração\n",
    "Dado esse contexto, escolha um único classificador, sem otimizar hiperparametros, treine e teste modelos considerando\n",
    "- Bag of Words (contagem), sem pré-processamento\n",
    "- TF-IDF, sem pré-processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "bagwords = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b = bagwords.fit_transform(text_train)\n",
    "X_text_b = bagwords.transform(text_test)\n",
    "X_train_tf = tfidf.fit_transform(text_train)\n",
    "X_text_tf = tfidf.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_b = X_train_b.shape\n",
    "d_train_tf = X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b;\n",
    "X_train_tf;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador Escolhido: Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_b, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do bagwords, foi: 78.93\n",
      "A acurácia do tf-idf, foi: 82.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_text_b)\n",
    "y_pred2 = model2.predict(X_text_tf)\n",
    "acuracia1 = round(accuracy_score(y_test,y_pred)*100,2)\n",
    "acuracia2 = round(accuracy_score(y_test,y_pred2)*100,2)\n",
    "print('A acurácia do bagwords, foi:' ,acuracia1)\n",
    "print('A acurácia do tf-idf, foi:' ,acuracia2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento \n",
    "\n",
    "As etapas de pré-processamento devem conter pelo menos:\n",
    "- lowercase\n",
    "- remoção de pontuação\n",
    "- remoção de números \n",
    "- remoção de stopwords (dica: utilize a biblioteca NLTK)\n",
    "- lematização ou stemming (apenas um dos dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowering(texto):\n",
    "    return texto.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remocao_pontuacao(texto):\n",
    "    pontuacao_retirada = \"\".join([i for i in texto if i not in string.punctuation])\n",
    "    return pontuacao_retirada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remocao_numeros(texto):\n",
    "    number_regex = '\\d+'\n",
    "    x = re.sub(number_regex, '', texto)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remocao_stopwords(texto):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    texto_stopwords = [j for j in texto.split() if j not in stopwords]\n",
    "    frase = \" \".join(texto_stopwords)\n",
    "    return frase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizacao(texto):\n",
    "    lemm_texto = [wordnet_lemmatizer.lemmatize(word) for word in texto.split()]\n",
    "    frase = \" \".join(lemm_texto)\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento(texto):\n",
    "    LO = lowering(texto)\n",
    "    RP = remocao_pontuacao(LO)\n",
    "    RN = remocao_numeros(RP)\n",
    "    RS = remocao_stopwords(RN)\n",
    "    LE = lemmatizacao(RS)\n",
    "    return LE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = []\n",
    "for i in range(len(text_train)):\n",
    "    p_process = preprocessamento(text_train[i])\n",
    "    X_train_p.append(p_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_p = []\n",
    "for i in range(len(text_test)):\n",
    "    p_process = preprocessamento(text_test[i])\n",
    "    X_test_p.append(p_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lerxstwamumdedu wheres thing subject car nntppostinghost racwamumdedu organization university maryland college park line wondering anyone could enlighten car saw day door sport car looked late early called bricklin door really small addition front bumper separate rest body know anyone tellme model name engine spec year production car made history whatever info funky looking car please email thanks il brought neighborhood lerxst'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\\nSubject: Need info on 88-89 Bonneville\\nOrganization: University at Buffalo\\nLines: 10\\nNews-Software: VAX/VMS VNEWS 1.41\\nNntp-Posting-Host: ubvmsd.cc.buffalo.edu\\n\\n\\n I am a little confused on all of the models of the 88-89 bonnevilles.\\nI have heard of the LE SE LSE SSE SSEI. Could someone tell me the\\ndifferences are far as features or performance. I am also curious to\\nknow what the book value is for prefereably the 89 model. And how much\\nless than book value can you usually get them for. In other words how\\nmuch are they in demand this time of year. I have heard that the mid-spring\\nearly summer is the best time to buy.\\n\\n\\t\\t\\tNeil Gandler\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vmbkubvmsdccbuffaloedu neil b gandler subject need info bonneville organization university buffalo line newssoftware vaxvms vnews nntppostinghost ubvmsdccbuffaloedu little confused model bonnevilles heard le se lse sse ssei could someone tell difference far feature performance also curious know book value prefereably model much le book value usually get word much demand time year heard midspring early summer best time buy neil gandler'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo extração\n",
    "Dado esse contexto, escolha um único classificador, sem otimizar hiperparametros, treine e teste modelos considerando\n",
    "- Bag of Words, com pré-processamento\n",
    "- TF-IDF, com pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pb = bagwords.fit_transform(X_train_p)\n",
    "X_text_pb = bagwords.transform(X_test_p)\n",
    "X_train_ptf = tfidf.fit_transform(X_train_p)\n",
    "X_text_ptf = tfidf.transform(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_b_pre = X_train_pb.shape\n",
    "d_train_tf_pre = X_train_ptf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_preprocessada = X_train_pb.shape\n",
    "d_test_preprocessada = X_text_pb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador Escolhido: Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression(max_iter=1000)\n",
    "model3.fit(X_train_pb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LogisticRegression()\n",
    "model4.fit(X_train_ptf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do bagwords após pre-processamento, foi: 79.63\n",
      "A acurácia do tf-idf após pre-processamento, foi: 83.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "y_pred3 = model3.predict(X_text_pb)\n",
    "y_pred4 = model4.predict(X_text_ptf)\n",
    "acuracia3 = round(accuracy_score(y_test,y_pred3)*100,2)\n",
    "acuracia4 = round(accuracy_score(y_test,y_pred4)*100,2)\n",
    "print('A acurácia do bagwords após pre-processamento, foi:' ,acuracia3)\n",
    "print('A acurácia do tf-idf após pre-processamento, foi:' ,acuracia4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação de Resultados - Tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resultados</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Dimensões</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acurácia BoW Sem Pré-Processamento</td>\n",
       "      <td>78.93</td>\n",
       "      <td>(11314, 130107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acurácia TF-IDF Sem Pré-Processamento</td>\n",
       "      <td>82.74</td>\n",
       "      <td>(11314, 130107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acurácia BoW Com Pré-Processamento</td>\n",
       "      <td>79.63</td>\n",
       "      <td>(11314, 111379)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acurácia TF-IDF Com Pré-Processamento</td>\n",
       "      <td>83.23</td>\n",
       "      <td>(11314, 111379)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Resultados  Acurácia        Dimensões\n",
       "0     Acurácia BoW Sem Pré-Processamento     78.93  (11314, 130107)\n",
       "1  Acurácia TF-IDF Sem Pré-Processamento     82.74  (11314, 130107)\n",
       "2     Acurácia BoW Com Pré-Processamento     79.63  (11314, 111379)\n",
       "3  Acurácia TF-IDF Com Pré-Processamento     83.23  (11314, 111379)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando um dataframe para apresentar os resultados\n",
    "# Ainda vou colocar o terceiro\n",
    "resultado1 = pd.Series({'Resultados': 'Acurácia BoW Sem Pré-Processamento', 'Acurácia': acuracia1, 'Dimensões': d_train_b})\n",
    "resultado2 = pd.Series({'Resultados': 'Acurácia TF-IDF Sem Pré-Processamento', 'Acurácia': acuracia2, 'Dimensões': d_train_tf})\n",
    "resultado3 = pd.Series({'Resultados': 'Acurácia BoW Com Pré-Processamento', 'Acurácia': acuracia3, 'Dimensões': d_train_b_pre})\n",
    "resultado4 = pd.Series({'Resultados': 'Acurácia TF-IDF Com Pré-Processamento', 'Acurácia': acuracia4, 'Dimensões': d_train_tf_pre})\n",
    "\n",
    "\n",
    "df_resultados = pd.DataFrame([resultado1,resultado2,resultado3,resultado4])\n",
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
